// Flashcards 002 - רגולריזציה ואופטימיזציה
export default {
  id: "flashcards-002",
  name: "רגולריזציה ואופטימיזציה",
  description: "כרטיסיות על שיטות רגולריזציה ואלגוריתמי אופטימיזציה",
  cards: [
    {
      front: "מהו ההבדל בין L1 ל-L2 רגולריזציה?",
      back: "L1 (Lasso): מוסיפה λΣ|w| לפונקציית העלות, יוצרת פתרונות sparse (מאפסת משקלים).\nL2 (Ridge): מוסיפה (λ/2)Σw² לפונקציית העלות, שומרת משקלים קטנים אך לא אפס."
    },
    {
      front: "מהו Early Stopping?",
      back: "טכניקת רגולריזציה שעוצרת את האימון כאשר ביצועי הוולידציה מפסיקים להשתפר ומתחילים להידרדר. מונעת overfitting על ידי עצירה לפני התאמת יתר."
    },
    {
      front: "מהו Data Augmentation?",
      back: "טכניקת רגולריזציה שמרחיבה את קבוצת האימון על ידי יצירת וריאציות של הנתונים הקיימים (סיבוב, חיתוך, שיקוף תמונות וכו'). מונעת overfitting ומשפרת הכללה."
    },
    {
      front: "מהו Gradient Descent?",
      back: "אלגוריתם אופטימיזציה שמעדכן את המשקלים בכיוון ההפוך לגרדיאנט של פונקציית העלות. בפונקציות לא-קמורות, עלול להתכנס למינימום מקומי או saddle point."
    },
    {
      front: "מהו SGD (Stochastic Gradient Descent)?",
      back: "וריאציה של Gradient Descent שמחשבת את הגרדיאנט על mini-batch במקום על כל הנתונים. מהיר יותר ומכניס רעש שיכול לעזור לצאת ממינימום מקומי."
    },
    {
      front: "מה המשמעות של Learning Rate?",
      back: "קצב הלמידה קובע את גודל הצעד בעדכון המשקלים. גבוה מדי: חוסר התכנסות. נמוך מדי: התכנסות איטית מאוד."
    },
    {
      front: "כיצד L2 משפיעה על עדכון המשקלים?",
      back: "עדכון המשקל: w_{t+1} = (1-αλ)w_t - α(∂Loss/∂w)\nהמשקל מוכפל ב-(1-αλ) בכל צעד, מה שגורם לדעיכה פרופורציונלית לגודל המשקל. לכן נקרא Weight Decay."
    },
    {
      front: "כיצד L1 משפיעה על עדכון המשקלים?",
      back: "עדכון המשקל: w_{t+1} = w_t - α(∂Loss/∂w) - αλ×sgn(w)\nהמשקל יורד בערך קבוע (לא פרופורציונלי לגודלו), מה שגורם למשקלים קטנים להתאפס לגמרי ויוצר sparsity."
    },
    {
      front: "מהו Generalization Error?",
      back: "שגיאת ההכללה - השגיאה הנמדדת על סט בדיקה שלא שימש לאימון. מודדת עד כמה המודל מצליח לבצע על נתונים חדשים שלא ראה."
    },
    {
      front: "מה ההבדל בין Validation Set ל-Test Set?",
      back: "Validation: משמש לכיוון hyperparameters (כמו λ) ולהחלטה מתי לעצור.\nTest: משמש רק להערכה סופית - אסור להשתמש בו לקבלת החלטות על המודל."
    },
    {
      front: "מהי שגיאת הכללה (Generalization)?",
      back: "התהליך שבו אלגוריתם הלמידה לומד מידע רלוונטי מסט האימון תוך התעלמות מרעש ומידע ספציפי לדאטה, מה שמאפשר ביצועים טובים על נתונים חדשים."
    },
    {
      front: "מהו Exponential Learning Rate Decay?",
      back: "הקטנת קצב הלמידה באופן אקספוננציאלי:\nα(t) = α(0) × γ^t\nכאשר γ < 1 (למשל 0.9). מאפשר צעדים גדולים בהתחלה וקטנים קרוב להתכנסות."
    },
    {
      front: "מהו Learning Rate Warmup?",
      back: "אסטרטגיה שמתחילים עם learning rate נמוך, מעלים אותו בהדרגה במשך כמה epochs ראשונים, ואז עוברים לדעיכה. עוזר לייצב את האימון בתחילתו."
    },
    {
      front: "כיצד Dropout מתפקד כאנסמבל?",
      back: "בכל איטרציה Dropout יוצר תת-רשת שונה (בחירה אקראית של נוירונים פעילים). בזמן inference הפלט הוא למעשה ממוצע של כל תתי-הרשתות האפשריות."
    },
    {
      front: "מדוע Dropout מונע co-adaptation?",
      back: "כיוון שכל נוירון עלול להיות מכובה, נוירונים לא יכולים להסתמך על נוירונים ספציפיים אחרים. כל נוירון נאלץ ללמוד features שימושיים באופן עצמאי, מה שיוצר redundancy."
    },
    {
      front: "מה קורה ל-Dropout בזמן Inference?",
      back: "Dropout מבוטל (כל הנוירונים פעילים), אבל הפלט מוכפל ב-(1-drop_rate) כדי לפצות על כך שבאימון נוירונים היו מכובים והסיגנל היה חלש יותר."
    },
    {
      front: "מתי משתמשים בשיטות רגולריזציה?",
      back: "כאשר יש סימנים ל-overfitting: Loss על האימון יורד אבל על validation עולה או לא משתפר. או מראש כשיש מעט דאטה ביחס למורכבות המודל."
    },
    {
      front: "מהו Xavier Initialization?",
      back: "שיטת אתחול משקלים מהתפלגות אחידה בטווח:\n[-√(6/(K_in + K_out)), √(6/(K_in + K_out))]\nמונעת vanishing/exploding gradients על ידי שמירה על variance קבוע."
    }
  ]
};
